{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 15 13:19:13 2019\n",
    "\n",
    "@author: 60888\n",
    "\"\"\"\n",
    "# For processing\n",
    "from dataInterfaceAssistant import dataInterfaceClass\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "# For plot\n",
    "from bqplot import DateScale, LinearScale, Axis, Lines, Scatter, Bars, Hist, Figure\n",
    "from bqplot.interacts import (\n",
    "    FastIntervalSelector, IndexSelector, BrushIntervalSelector,\n",
    "    BrushSelector, MultiSelector, LassoSelector, PanZoom, HandDraw\n",
    ")\n",
    "from traitlets import link\n",
    "from ipywidgets import ToggleButtons, VBox, HTML\n",
    "\n",
    "DIA = dataInterfaceClass()\n",
    "\n",
    "def spongeCityService(start,stop,levelThreshold,maxThreshold,levelSlopeAngle,dataOffset,bufferLength,resultAttribute):\n",
    "    mille = 1000 # magic number that is used to correct Alibaba UNIX time to standard UNIX time\n",
    "    timeRange = [start,stop]\n",
    "    levelThreshold = levelThreshold\n",
    "    levelSlopeAngle = levelSlopeAngle\n",
    "    dataOffset = int(dataOffset)\n",
    "    bufferLength = int(bufferLength)\n",
    "    \n",
    "    # Import data \n",
    "    # parse json data frame to a panda dataframe using: getDataToWorkWith(\"data from the API\")\n",
    "    requestedData, statusInfoRequest, reasonCodeRequest = DIA.getDataToWorkWith(timeRange)\n",
    "    #print(len(requestedData))\n",
    "    #print(statusInfoRequest)#, reasonCodeRequest)\n",
    "    #print(requestedData)\n",
    "    # convert it (if you like) to a panda dataframe for algoritmic convinience: postProcessedDataBack(\"your converted data\")\n",
    "    requestedDataframe = DIA.jsonToDataframe(requestedData, resultAttribute)\n",
    "    # Do basic repair\n",
    "    requestedDataframe.isnull().values.any()\n",
    "    # mirror baseline input to output and change only what you need to change\n",
    "    processedDataframe = requestedDataframe\n",
    "    \n",
    "    \"\"\" ####### Do the data \"magic\" ########### \"\"\" \n",
    "    # Remember to add unit test of this particular piece of code - sanity check is only done on data request and data post\n",
    "    degree = 1\n",
    "    linearRegressionModel = linear_model.LinearRegression()\n",
    "  \n",
    "    for timeIndex in range(0, len(requestedDataframe.get('water_level').values[dataOffset:])-bufferLength, bufferLength):\n",
    "        \n",
    "        # Get data to work with\n",
    "        x = requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].reshape(len(requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]), 1)\n",
    "        y = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].reshape(len(requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]), 1)\n",
    "        x = np.divide(x, mille)\n",
    "        \n",
    "        xx = requestedDataframe.get('unix_time').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].astype('int')\n",
    "        yy = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength].astype('float')\n",
    "        xx = np.divide(xx, mille)\n",
    "        \n",
    "        # Make line fit / linear regression\n",
    "        weights = np.polyfit(np.array(xx),np.array(yy), degree)\n",
    "        model = np.poly1d(weights)\n",
    "        \n",
    "        #linearRegressionModel.fit(x,y)\n",
    "        #linearRegressionModelPrediction = linearRegressionModel.predict(list(test.get('time').values))\n",
    "        \n",
    "        #bufferSlope = math.degrees(math.atan(linearRegressionModel.coef_))\n",
    "        bufferSlope = weights[0]\n",
    "        #bufferMean = np.mean(y)\n",
    "        bufferMean = np.mean(yy)\n",
    "\n",
    "        # Make primitive overflow classification\n",
    "        if bufferMean >= levelThreshold and bufferSlope > levelSlopeAngle:\n",
    "            #print('yes')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]\n",
    "        elif bufferMean >= maxThreshold and bufferSlope >= 0:\n",
    "            #print('yes')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = requestedDataframe.get('water_level').values[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength]\n",
    "        else:\n",
    "            #print('no')\n",
    "            processedDataframe.loc[dataOffset+timeIndex:dataOffset+timeIndex+bufferLength-1,resultAttribute] = float(-1)\n",
    "            \n",
    "    \"\"\" ####### Please stop your \"magic\" ########### \"\"\"    \n",
    "    # Export data\n",
    "    processedData = DIA.dataframeToJson(processedDataframe)\n",
    "    #print(processedData)\n",
    "    # ship it away with: postProcessedDataBack(\"your converted data\")\n",
    "    statusInfoPost, reasonCodePost = DIA.postProcessedDataBack(processedData)\n",
    "    #print(statusInfoPost)#, reasonCode)\n",
    "    if(statusInfoRequest == DIA.sanityCheck() and statusInfoPost == DIA.sanityCheck() and len(requestedData) > 0):\n",
    "        sanityCheck = True\n",
    "    else:\n",
    "        sanityCheck = False\n",
    "            \n",
    "    print(\"The operation went well:\", sanityCheck)\n",
    "    return processedDataframe, sanityCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeOffset = 72 # Number of hours to take into account in the overflow post process\n",
    "localDate = datetime.datetime.now() - datetime.timedelta(hours = timeOffset)\n",
    "localDateStart = localDate.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "localDatePrevious = localDate + datetime.timedelta(hours = timeOffset)\n",
    "localDateStop = localDatePrevious.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "#utcDate = datetime.datetime.utcnow();\n",
    "start = '2019-06-04T0:55:52Z' # fixed time stamp used for debugging\n",
    "#start = localDateStart\n",
    "#print(start)\n",
    "stop = '2019-06-05T19:28:52Z' # fixed time stamp used for debugging\n",
    "#stop = localDateStop\n",
    "dataOffset = 0 # handle bad data engineering work - if you trust your data engineer set it to: 0\n",
    "bufferLength = 30 # number of samples per overflow iteration evalution\n",
    "levelThreshold = 0.45 # meters of water in pump pit\n",
    "maxThreshold = 0.90 # meters of water in pump pit\n",
    "levelSlopeAngle = 0.000085 # water increase factor in pump pit\n",
    "resultAttribute = 'overflow' # explictly declare your result attribute\n",
    "debugMode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation went well: True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data, test = spongeCityService(start,stop,levelThreshold, maxThreshold, levelSlopeAngle,dataOffset,bufferLength,resultAttribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define a function that will be called when the selectors are interacted with\n",
    "def index_change_callback(change):\n",
    "    db_index.value = 'The selected date is ' + str(change.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761d92ce6f334c38ae7ff0b61e25514c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='[]'), Figure(axes=[Axis(label='Index', scale=DateScale()), Axis(label=' water_levelâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## First we define a Figure\n",
    "dt_x_fast = DateScale()\n",
    "lin_y = LinearScale()\n",
    "\n",
    "x_ax = Axis(label='Index', scale=dt_x_fast)\n",
    "x_ay = Axis(label=(' water_level'), scale=lin_y, orientation='vertical')\n",
    "lc = Lines(x=data.unix_time, y=data.water_level, scales={'x': dt_x_fast, 'y': lin_y}, colors=['orange'])\n",
    "lc_2 = Lines(x=data.unix_time, y=data.flow_rate, scales={'x': dt_x_fast, 'y': lin_y}, colors=['blue'])\n",
    "lc_3 = Lines(x=data.unix_time, y=data.overflow, scales={'x': dt_x_fast, 'y': lin_y}, colors=['red'])\n",
    "\n",
    "db_index = HTML(value='[]')\n",
    "\n",
    "## Now we try a selector made to select all the y-values associated with a single x-value\n",
    "index_sel = IndexSelector(scale=dt_x_fast, marks=[lc, lc_2, lc_3])\n",
    "index_sel.observe(index_change_callback, names=['selected'])\n",
    "fig_index_sel = Figure(marks=[lc, lc_2, lc_3], axes=[x_ax, x_ay], title='Index Selector Example', interaction=index_sel)\n",
    "VBox([db_index, fig_index_sel])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
